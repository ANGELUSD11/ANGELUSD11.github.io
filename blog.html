<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog - ANGELUS11</title>
    <meta name="description" content="Blog de desarrollo de ANGELUS11.">
    <meta name="author" content="ANGELUS11">
    <link rel="icon" type="image/png" href="icons/icon_glow.png">
    
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <!-- Prism.js Theme -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="blog-styles.css">
</head>
<body class="bg-dark text-light">

    <nav class="navbar bg-dark-subtle py-3">
        <div class="container d-flex justify-content-between align-items-center">
            <!-- Left side: Home button -->
            <ul class="navbar-nav">
                <li class="nav-item">
                    <a class="nav-link text-primary" href="index.html"><i class="fas fa-home me-1"></i><span data-es="Inicio" data-en="Home"></span></a>
                </li>
            </ul>

            <!-- Right side: Language switcher -->
            <div class="language-switcher">
                <button id="langBtn" class="btn btn-outline-primary">
                    <i class="fas fa-globe"></i> <span id="langText">EN</span>
                </button>
            </div>
        </div>
    </nav>

    <main class="container py-5">
        <h1 class="text-center text-primary mb-5">
            <i class="fas fa-code me-2"></i>
            <span data-es="Blog de Desarrollo" data-en="Development Blog"></span>
        </h1>

        <div class="blog-container">
                        <article class="blog-post card bg-dark-subtle border-primary mb-4">
                <div class="card-body">
                    <h2 class="card-title text-primary" data-es="Algebra lineal para Machine Learningü§ñ" data-en="Linear Algebra for Machine Learningü§ñ"></h2>
                    <p class="card-subtitle mb-2 text-muted" data-es="18 de noviembre de 2025" data-en="November 18, 2025"></p>
                    <div class="card-text">
                        <p data-es="Esta entrada corresponde a una libreta de jupyter explicando a detalle los distintos elementos que conforman las estructuras de datos usadas en algebra lineal para machine learning." data-en="This entry corresponds to a Jupyter notebook explaining in detail the different elements that make up the data structures used in linear algebra for machine learning."></p>
                        <a class="btn btn-outline-info btn-sm mb-3 toggle-btn" data-bs-toggle="collapse" href="#ML-content" role="button" aria-expanded="false" aria-controls="ML-content">
                            <span data-es="Mostrar m√°s" data-en="Show more"></span> <i class="fas fa-chevron-down"></i>
                        </a>
                        <div class="collapse" id="ML-content">
                            <pre><code class="language-python">
                                #un escalar es un tipo de variable que solo tiene un valor, puede ser int, float, str, bool
                                #es simplemente un n√∫mero real que se utiliza para: multplicar vectores o matrices o cambiar su magnitud
                                escalar = 2.65
                                print(f"Escalar float: {escalar}")
                                escalar_bool = True
                                print(f"Escalar bool: {escalar_bool}")

                                #Verificar tipos de variables
                                print(f"Tipo de escalar: {type(escalar)}")
                                print(f"Tipo de escalar: {type(escalar_bool)}")

                                #un vector es un conjunto de numeros reales
                                #Una matriz es una estructura bidimensional de n√∫meros reales, que puede representarse como un conjunto ordenado de vectores fila o columna.
                                #Un tensor es una estructura multidimensional que generaliza a vectores y matrices a m√°s dimensiones.

                                #importaciones
                                import numpy as np

                                vector = np.array([1, 2, 3, 4])
                                print(f"Vector: {vector}")
                                #.shape() nos devuelve las dimensiones del objeto en cuesti√≥n
                                print(f"\nDimensiones de Vector: {np.shape(vector)}") #(4,) -> 4 elementos
                                print(f"\nCantidad de elementos en Vector: {np.size(vector)}")

                                matriz = np.array([[1, 2, 3],
                                                    [4, 5, 6],
                                                    [7, 8, 9]])

                                print(f"\nMatriz: {matriz}")
                                print(f"\nDimensiones de Matr√≠z: {np.shape(matriz)}") #(3, 3) -> 3 filas, 3 columnas
                                print(f"\nCantidad de elementos en Matr√≠z: {np.size(matriz)}")

                                tensor = np.array([
                                    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                                    [[10, 11, 12], [13, 14, 15], [16, 17, 18]],
                                    [[19, 20, 21], [22, 23, 24], [25, 26, 27]]
                                ])
                                print(f"\nTensor:\n{tensor}")
                                print(f"\nDimensiones de Tensor: {np.shape(tensor)}") #(3, 3, 3) ->3 matrizes, 3 filas, 3 columnas
                                print(f"\nCantidad de elementos en Tensor: {np.size(tensor)}")

                                import matplotlib.pyplot as plt

                                #graficar el tensor estructurado mediante escala de grises
                                plt.imshow(tensor, interpolation='nearest')
                                plt.show()
                            </code></pre>

                            <figure class="figure-text-center">
                                <img src="images/ML images/grey_scale.webp" class="figure-img img-fluid rounded">
                                <figcaption class="figure-caption text-light-emphasis"></figcaption>
                            </figure>

                            <pre><code class="language-python">
                                tensor_rgb = np.array([
                                    [[0, 255, 0], [0, 255, 0], [0, 255, 0]],
                                    [[0, 159, 193], [0, 159, 193], [0, 159, 193]],
                                    [[0, 0, 255], [0, 0, 255], [0, 0, 255]]
                                ])

                                #matplotlib interpreta cada vector como colores rgb
                                plt.imshow(tensor_rgb, interpolation='nearest')
                                plt.show()
                            </code></pre>

                            <figure class="figure text-center">
                                <img src="images/ML images/rgb_example.webp" class="figure-img img-fluid rounded">
                                <figcaption class="figure-caption text-light-emphasis"></figcaption>
                            </figure>

                            <pre><code class="language-python">
                                #transposici√≥n de vectores y matrices
                                escalar = 2.65

                                vector = np.array([1, 2, 3, 4])
                                vector1  = np.array([5, 6, 7, 8])

                                matriz = np.array([[1, 2],
                                                [3, 4],
                                                [5, 6]])
                                print(f"Matr√≠z original:\n{matriz}")
                                print(f"\nDimensiones de la Matr√≠z: {np.shape(matriz)}")
                                matriz_t = np.transpose(matriz)
                                print(f"\nMatriz transpocisionada:\n{matriz_t}")
                                print(f"\nDimensiones de la Matr√≠z transposicionada: {np.shape(matriz_t)}")
                                tensor = np.array([
                                    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                                    [[10, 11, 12], [13, 14, 15], [16, 17, 18]],
                                    [[19, 20, 21], [22, 23, 24], [25, 26, 27]]
                                ])
                                print(f"\nTensor:\n{tensor}")
                                print(f"\nDimensiones del tensor: {np.shape(tensor)}")
                                tensor_t = np.transpose(tensor)
                                print(f"\nTensor trasposicionado:\n{tensor_t}")
                                print(f"\nDimensiones del tensor transposicionado:\n{np.shape(tensor_t)}")

                                #suma de matr√≠ces (IMPORTANTE: para hacer una suma entre 2 o m√°s matrices, vectores o tensores, tienen que tener las mismas dimensiones, en este caso (2x2))
                                a = np.array([[1, 2, 3], [4, 5, 6],
                                            [7, 8, 9], [10, 11, 12]])
                                print(f"\nDimensiones de la Matr√≠z a: {np.shape(a)}")

                                b = np.array([[13, 14, 15], [16, 17, 18],
                                            [19, 20, 21], [22, 23, 24]])
                                print(f"\nDimensiones de la Matr√≠z b: {np.shape(b)}")

                                c = a + b

                                print(f"\nSuma de las 2 matrices:\n{c}")

                                d = matriz + escalar

                                print(f"\nSuma de la matr√≠z m√°s el escalar:\n{d}")

                                #suma de vectores
                                e = vector + vector1
                                print(f"\nSuma de 2 vectores:\n{e}")

                                #suma de vectores o matrices con dimensiones distintas
                                #reglas del broadcasting de Python

                                vector2 = np.array([3, 4, 5]) # vector con 3 valores

                                print(f"\nVector 2 inicial:\n{vector2}")

                                matriz2 = np.array([[1, 2], # matr√≠z de dimensi√≥n 3x2
                                                    [3, 4],
                                                    [5, 6]])
                                print(f"\nMatr√≠z 2 inicial:\n{matriz2}")

                                matriz2_t = np.transpose(matriz2) # matr√≠z de dimensi√≥n 2x3
                                print(f"\nMatr√≠z 2 transposicionada:\n{matriz2_t}")

                                #lo que queremos hacer:
                                #sumar      ([3, 4, 5]) + ([[1, 2],   ##ESTO NO SE PUEDE DEBIDO A QUE NO PODEMOS ASIGNAR CORRECTAMENTE LOS 3 VALORES NECESARIOS PARA CADA OPERACI√ìN
                                #                           [3, 4],
                                #                           [5, 6]])

                                #sumar      ([3, 4, 5]) + [[1 3 5]  ##ESTO SI SE PUEDE DEBIDO A QUE PODEMOS ASIGNAR CORRECTAMENTE LOS 3 VALORES NECESARIOS PARA CADA OPERACI√ìN
                                #                          [2 4 6]] ##EL BROADCASTING SE ENCARGA DE EXTENDER UN VECTOR O MATR√çZ QUE LO NECESITE PARA PODER HACER LA OPERACI√ìN

                                #efectuamos la suma correspondiente

                                suma_final = vector2 + matriz2_t
                                print(f"\nSuma final resultante:\n{suma_final}")

                                import matplotlib.pyplot as plt
                                import matplotlib.image as mpimg
                                #multiplicaci√≥n de matrices y vectores
                                escalar = 2.65 #escalar = Œª

                                vector = np.array([1, 2])
                                vector1  = np.array([5, 6, 7, 8])

                                matriz = np.array([[1, 2],
                                                [3, 4],
                                                [5, 6]])

                                multiplicacion = vector * matriz # EN ESTE CASO PYTHON HACE BROADCASTING INTERNAMENTE
                                print(f"\n Resultado de la multiplicaci√≥n:\n{multiplicacion}")

                                #producto interno nos devuelve un vector con los valores resultantes de la suma de los productos de cada fila

                                #           ([[1, 2],               1*1 + 2*2 = 5
                                #             [3, 4], * ([1, 2]) =  3*1 + 4*2 = 11 = [5, 11, 17]
                                #             [5, 6]])              5*1 + 6*2 = 17

                                producto_interno = np.dot(matriz, vector)
                                print(f"\nProducto interno resultante:\n{producto_interno}")

                                #multiplicaci√≥n entre matr√≠ces
                                matriz_a = np.array([[1, 2, 3],
                                                    [4, 5, 6],
                                                    [7, 8, 9],
                                                    [10, 11, 12]])
                                print(f"\nDimensiones de matr√≠z a: {np.shape(matriz_a)}")

                                matriz_b = np.array([[13, 14, 15],
                                                    [16, 17, 18],
                                                    [19, 20, 21],
                                                    [22, 23, 24]])
                                print(f"\nDimensiones de matr√≠z b: {np.shape(matriz_b)}")

                                matriz_c = np.array([[2, 3],
                                                    [5, 7],
                                                    [11, 13]])
                                print(f"\nDimensiones de matr√≠z c: {np.shape(matriz_c)}")

                                multip = matriz_a * matriz_b
                                print(f"\nResultado de la multiplicaci√≥n elemento por elemento entre 2 matr√≠ces:\n{multip}")

                                matriz_b_t = np.transpose(matriz_b)
                                print(f"\nMatr√≠z b transpuesta:\n{matriz_b_t}")
                                print(f"\nDimensiones de la matr√≠z b transpuesta:\n{np.shape(matriz_b_t)}")

                                multip = np.dot(matriz_a, matriz_b_t)#multiplicaci√≥n de matrices compatible (4*3)(3*4)
                                print(f"\nResultado de la multiplicaci√≥n tradicional entre matriz a y matriz b:\n{multip}")

                                #producto interno matriz_a * matriz_c ##CUANDO TENGO, COMO EN ESTE CASO, UNA ALINEACI√ìN EN 2 VALORES, SE PUEDE EFECTUAR EL PI (4, 3)(3, 2)
                                #                   ([[1, 2, 3],          ([[2, 3],       1*2 + 2*5 + 3*11 = 45  -  1*3 + 2*7 + 3*13 = 56                 [[45 56]
                                #                     [4, 5, 6],      *     [5, 7],    =  4*2 + 5*5 + 6*11 = 99  -  4*3 + 5*7 + 6*13 = 125          =      [99 125]
                                #                     [7, 8, 9],            [11, 13]])    7*2 + 8*5 + 9* 11 = 153  -  7*3 + 8*7 + 9*13 = 194               [153 194]
                                #                     [10, 11, 12]])                      10*2 + 11*5 + 12*11 = 207  -  10*3 + 11*7 + 12*13 = 263          [207 263]]

                                producto_interno = np.dot(matriz_a, matriz_c)
                                print(f"\nProducto interno resultante:\n{producto_interno}")


                                img = mpimg.imread('producto interno.png')
                                plt.figure(figsize=(10, 10))
                                plt.imshow(img)
                                plt.show()

                                #propiedades del producto interno

                                A = np.array([[2, 3],
                                            [5, 7],
                                            [11, 13]])
                                print(f"\nDimensiones de la matr√≠z A:\n{np.shape(A)}")

                                B = np.array([[1, 3],
                                            [2, 1]])
                                print(f"\nDimensiones de la matr√≠z B\n{np.shape(B)}")

                                C = np.array([[3, 1],
                                            [4, 2]])
                                print(f"Dimensiones de la matr√≠z C:\n{np.shape(C)}")
                                #propiedad asociativa
                                #RECORDATORIO: Para que puedas multiplicar dos matrices A*B, se debe cumplir:
                                #El n√∫mero de columnas de A = n√∫mero de filas de B    Si A es de forma (m * n) y B es de forma (n * p), entonces AB es de forma (m √ó p)
                                #El orden de agrupaci√≥n no afecta el resultado. (A * B) * C = A * (B * C)

                                #A*(B*C) = (A*B)*C

                                #A * (B * C)
                                ABC = A.dot(B.dot(C))
                                print(f"\nMultiplicaci√≥n: A*(B*C):\n{ABC}")

                                #(A * B) * C
                                AB_C = A.dot(B).dot(C)
                                print(f"\nMultiplicaci√≥n: (A*B)*C:\n{AB_C}")

                                #comprobamos la igualdad entre las 2 matr√≠ces resultantes
                                print(f"\nIgualdad entre ABC y AB_C: {np.array_equal(ABC, AB_C)}")

                                # La propiedad distributiva establece que:
                                # A * (B + C) = (A * B) + (A * C)
                                # Esto significa que la multiplicaci√≥n de una matriz A por la suma de dos matrices B y C
                                # es igual a la suma de la multiplicaci√≥n de A por B y la multiplicaci√≥n de A por C.

                                D = A.dot(B+C)
                                E = (A.dot(B)) + (A.dot(C))

                                print(f"\nA*(B+C):\n{D}")
                                print(f"\n(A*B)+(A*C):\n{E}")

                                #comprobamos la igualdad entre las 2 matrices resultantes
                                print(f"\nIgualdad entre D y E: {np.array_equal(D, E)}")

                                # La propiedad conmutativa establece que:
                                # A * B = B * A
                                # Esto significa que el orden de la multiplicaci√≥n no afecta al resultado.
                                # Sin embargo, esta propiedad no se cumple en la multiplicaci√≥n de matrices,
                                # pero s√≠ en la multiplicaci√≥n de vectores (producto escalar).

                                F = np.dot(B, C)
                                print(f"\nProducto interno B*C:\n{F}\ny sus dimensiones:\n{np.shape(F)}")
                                G = np.dot(C, B)
                                print(f"\nProducto interno C*B:\n{G}\ny sus dimensiones:\n{np.shape(G)}")

                                #comprobamos la igualdad entre las 2 matrices resultantes
                                print(f"\nIgualdad entre F y G: {np.array_equal(F, G)}") ##FALSE, NO APLICA CON MULTIPLICACI√ìN DE MATRICES

                                #LA MULTIPLICACI√ìN DE VECTORES SI ES CONMUTATIVA

                                vector1 = np.array([3, 7]) #multiplicaci√≥n ([3, 7]) * ([3, 5]) = 3*3 + 7*5 = 44
                                vector2 = np.array([3, 5]) #multiplicaci√≥n ([3, 5]) * ([3, 7]) = 3*3 + 5*7 = 44

                                H = np.dot(vector1, vector2)
                                print(f"\nProducto interno vector1 * vector2:\n{H}\ny sus dimensiones:\n{np.shape(H)}")
                                I = np.dot(vector2, vector1)
                                print(f"\nProducto interno vector2 * vector1:\n{I}\ny sus dimensiones:\n{np.shape(I)}")
                            </code></pre>
                        </div>
                    </div>
                </div>
            </article>
            <article class="blog-post card bg-dark-subtle border-primary mb-4">
                <div class="card-body">
                    <h2 class="card-title text-primary" data-es="Creaci√≥n del Blog" data-en="Blog Creation"></h2>
                    <p class="card-subtitle mb-2 text-muted" data-es="15 de noviembre de 2025" data-en="November 15, 2025"></p>
                    <div class="card-text">
                        <p data-es="¬°Bienvenido a mi nuevo blog! He decidido crear este espacio para documentar el proceso de desarrollo de mis proyectos, compartir ideas y publicar los avances." data-en="Welcome to my new blog! I've decided to create this space to document the development process of my projects, share ideas, and post updates."></p>
                        <p data-es="Para empezar, he creado esta misma p√°gina usando HTML y Bootstrap, manteniendo el estilo de mi portafolio principal. Aqu√≠ podr√°s ver c√≥mo evolucionan mis proyectos como <strong>TDMBOTüí†</strong>, <strong>Berto AIüå±</strong> y otros experimentos en los que trabaje." data-en="To start, I've created this very page using HTML and Bootstrap, maintaining the style of my main portfolio. Here you'll be able to see how my projects like <strong>TDMBOTüí†</strong>, <strong>Berto AIüå±</strong>, and other experiments I work on evolve."></p>
                    </div>
                </div>
            </article>

            <article class="blog-post card bg-dark-subtle border-info mb-4">
                <div class="card-body">
                    <h2 class="card-title text-info" data-es="Proceso de desarrollo de RobTopLvlIDüîé" data-en="Development Process for RobTopLvlIDüîé"></h2>
                    <p class="card-subtitle mb-2 text-muted" data-es="22 de mayo de 2025" data-en="May 22, 2025"></p>
                    
                    <div class="card-text">
                        <p data-es="Hace unos meses, cuando comenc√© a explorar el campo de la inteligencia artificial, me pregunt√© si ser√≠a posible desarrollar un modelo capaz de reconocer niveles de Geometry Dash. Mi objetivo no era aprovechar esto para obtener una ventaja injusta en Sparky, especialmente considerando las evidentes limitaciones de hardware‚Äî incluso utilizando recursos en la nube.
                        Finalmente, decid√≠ basar el proyecto en el modelo pre-entrenado MobileNetV2 de Keras, aprovechando redes neuronales convolucionales para el reconocimiento de im√°genes. El c√≥digo completo puede encontrarse en el repositorio GDLvlDetector.

                        Inicialmente intent√© construir la red desde cero usando TensorFlow, y sorprendentemente funcion√≥ bastante bien reconociendo alrededor de dos a cinco niveles como m√°ximo. Sin embargo, el principal reto con este enfoque fue la gran cantidad de datos requerida y las limitaciones de hardware.
                        En las siguientes secciones explicar√© cada fase del proceso de entrenamiento que llev√© a cabo." 
                        
                        data-en="
                        A few months ago, as I began exploring the field of artificial intelligence, I wondered whether it would be possible to develop a model capable of recognizing Geometry Dash levels. My goal was not to exploit this for unfair advantage in Sparky, especially considering the evident hardware limitations‚Äîeven when utilizing cloud resources. Ultimately, I decided to base the project on the pre-trained MobileNetV2 model from Keras, leveraging convolutional neural networks for image recognition. The complete code can be found in the repository GDLvlDetector. 
                        
                        Initially, I attempted to build the network from scratch using TensorFlow, which surprisingly performed quite well in recognizing around two to five levels at most. However, the primary challenge with this approach was the sheer volume of data required and the hardware constraints. In the following sections, I will explain each phase of the training process I undertook."></p>

                        <a class="btn btn-outline-info btn-sm mb-3 toggle-btn" data-bs-toggle="collapse" href="#robtop-content" role="button" aria-expanded="false" aria-controls="robtop-content">
                            <span data-es="Mostrar m√°s" data-en="Show more"></span> <i class="fas fa-chevron-down"></i>
                        </a>

                        <div class="collapse" id="robtop-content">
                            <div class="ratio ratio-16x9 my-4 video-frame">
                                <iframe src="https://www.youtube.com/embed/n_L2AG_-dxs?si=HRqAvSSNpA7IZpsU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                            </div>

                            <p data-es="Como en cualquier proyecto de machine learning, el primer paso que debe realizarse‚Äîy el que en √∫ltima instancia determinar√° la calidad del modelo‚Äîes reunir los datos de entrenamiento.

                            Para este proyecto, pas√© varios d√≠as grabando todos los niveles que el modelo deber√≠a reconocer posteriormente usando im√°genes. Sin embargo, no pod√≠a entrenar el modelo usando directamente el metraje de los videos, lo que nos lleva al segundo paso." 
                            
                            data-en="As with any machine learning project, the initial step that must be taken‚Äîand the one that will ultimately determine the quality of the model‚Äîis gathering the training data. 
                            
                            For this project, I spent several days recording all the levels that the model would later recognize using images. However, I could not train the model using video footage directly, which leads us to the second step.
                            The proper way to train a convolutional neural network is by using images. Therefore, I extracted frames from the videos I had recorded earlier. Naturally, I didn‚Äôt do this manually but instead used OpenCV with the following script:"></p>

                            <pre><code class="language-python">
                                import os
                                import cv2

                                def extract_frames(video_path, output_folder, interval=30):
                                    os.makedirs(output_folder, exist_ok=True)

                                    cap = cv2.VideoCapture(video_path)

                                    frame_count = 0
                                    saved_frames = 0

                                    while cap.isOpened(): 
                                        ret, frame = cap.read()
                                        if not ret:
                                            break

                                        if frame_count % interval == 0:
                                            filename = os.path.join(output_folder, f"{os.path.basename(video_path).split('.')[0]}_frame_{saved_frames}.jpg")
                                            cv2.imwrite(filename, frame)
                                            saved_frames += 1

                                        frame_count += 1

                                    cap.release()
                            </code></pre>
                            <p data-es="En el paso anterior, las im√°genes extra√≠das de los fotogramas fueron guardadas ordenadamente en carpetas nombradas seg√∫n cada nivel.
                            Ahora es necesario preparar los datos de la manera m√°s √≥ptima para usarlos con el modelo MobileNetV2, de forma que durante el proceso de convoluci√≥n pueda clasificar y reconocer patrones correctamente.
                            Esto implica tomar en cuenta varios aspectos, como:
                            tama√±o de las im√°genes, tama√±o de los lotes, tama√±os de los vectores, canales de color y muchos otros detalles tediosos pero esenciales."
                            
                            data-en="In the previous step, the images from the frames were saved in an orderly manner into folders named after each level. Now, it is necessary to prepare the data in the most optimal way for use with the MobileNetV2 model, so that during the convolution process it can classify and recognize patterns correctly. This involves taking several aspects into account, such as image size, batch size, vector sizes, color channels, and many other tedious but essential details. The following script details this process:"></p>
                            <pre><code class="language-python">
                                import tensorflow as tf
                                import numpy as np
                                import json
                                import matplotlib.pyplot as plt
                                from keras.src.legacy.preprocessing.image import ImageDataGenerator
                                from keras.src.callbacks import EarlyStopping, ModelCheckpoint
                                from keras.src.applications.mobilenet_v2 import preprocess_input, MobileNetV2
                                from keras.src import layers, models

                                # Path to the train data
                                data_path = "vidframes"

                                # Callbacks
                                callbacks = [
                                    EarlyStopping(patience=10, restore_best_weights=True),
                                    ModelCheckpoint("best_model.keras", save_best_only=True)
                                ]

                                # Data Augmentation + Preprocess MobileNetV2
                                datagen = ImageDataGenerator(
                                    preprocessing_function=preprocess_input,
                                    validation_split=0.2,
                                    rotation_range=15,
                                    width_shift_range=0.1,
                                    height_shift_range=0.1,
                                    shear_range=0.1,
                                    zoom_range=0.2,
                                    horizontal_flip=True,
                                    brightness_range=[0.8, 1.2],
                                    fill_mode='nearest'
                                )

                                train_data = datagen.flow_from_directory(
                                    data_path,
                                    target_size=(160, 160),  # Size for MobileNetV2
                                    batch_size=32,
                                    class_mode='categorical',
                                    subset='training'
                                )

                                val_data = datagen.flow_from_directory(
                                    data_path,
                                    target_size=(160, 160),
                                    batch_size=32,
                                    class_mode='categorical',
                                    subset='validation'
                                )
                            </code></pre>

                            <p data-es="En este paso, el modelo ya est√° listo para comenzar su proceso de entrenamiento.
                            Despu√©s de preparar los datos, la red neuronal puede generalizar m√°s informaci√≥n para reconocer casos especiales, como si la imagen est√° rotada o deformada, entre otros.

                            En este punto uso un modelo pre-entrenado de Keras llamado MobileNetV2. Al cargarlo, esto me permite entrenar mi modelo utilizando la t√©cnica de transfer learning, evitando crear mi propia red neuronal convolucional desde cero y lidiar con todos los problemas que eso implica.
                            
                            Importar modelos pre-entrenados MobileNetV2 desde keras y cargar el modelo en una variable:"

                            data-en="Model Training In this step, the model is ready to begin its training process. After data preparation, the neural network can generalize to more information to order to recognize more special cases, such as if an image if rotated or deformed, among others. At this point i use an pre-trained Keras model called MobileNetV2. By loading it, this will me train my model using the transfer learning technique so i don't create my own Convolutional Neuronal Network from scratch and deal with all the problems that entails.

                            Import MobileNetV2 Pre-trained models from keras and load the model in a variable:"></p>

                            <pre><code class="language-python">
                                from keras.src.legacy.preprocessing.image import ImageDataGenerator
                                from keras.src.callbacks import EarlyStopping, ModelCheckpoint
                                from keras.src.applications.mobilenet_v2 import preprocess_input, MobileNetV2
                                from keras.src import layers, models

                                base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))
                            </code></pre>

                            <p data-es="Proceso de Transfer Learning y configuraci√≥n"
                            data-en="Transfer Learning Process and configutation"></p>

                            <pre><code class="language-python">
                                for layer in base_model.layers:
                                    layer.trainable = False

                                for layer in base_model.layers[-30:]:  # Latest 30 layers
                                    layer.trainable = True

                                # Complete Model
                                model = models.Sequential([
                                    base_model,
                                    layers.GlobalAveragePooling2D(),
                                    layers.Dense(256, activation='relu'),
                                    layers.Dropout(0.5),
                                    layers.Dense(train_data.num_classes, activation='softmax')  
                                ])
                            </code></pre>

                            <p data-es="Proceso de compilaci√≥n y entrenamiento"
                            data-en="Compile and training process"></p>

                            <pre><code class="language-python">
                                # Compile
                                model.compile(
                                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
                                    loss='categorical_crossentropy',
                                    metrics=['accuracy']
                                )

                                # Training
                                history = model.fit(train_data, validation_data=val_data, epochs=50, callbacks=callbacks)
                                with open("train_history.json", "w").
                                    json.dump(history.history, f)

                                # Save Model .keras
                                model.save("gd_level_classifier.keras")
                            </code></pre>
                            
                        </div>
                    </div>
                </div>
            </article>

        </div>
    </main>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Prism.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/normalize-whitespace/prism-normalize-whitespace.min.js"></script>
    <!-- Custom JS -->
    <script src="portfolio-script.js"></script>
    <script>
        // Configuraci√≥n de Prism Normalize Whitespace
        Prism.plugins.NormalizeWhitespace.setDefaults({
            'remove-trailing': true,
            'remove-indent': true,
            'left-trim': true,
            'right-trim': true,
        });
    </script>
</body>
</html>