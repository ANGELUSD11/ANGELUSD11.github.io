<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog - ANGELUS11</title>
    <meta name="description" content="Blog de desarrollo de ANGELUS11.">
    <meta name="author" content="ANGELUS11">
    <meta name="keywords" content="ANGELUS11, ANGELUSD11, developer, Blog">
    <meta property="og:image" content="https://angelus11.dev/images/patrondiamantes.jpg" />
    <link rel="icon" type="image/png" href="icons/icon_glow.png">
    
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <!-- Prism.js Theme -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="blog-styles.css">
</head>
<body class="bg-dark text-light">

    <nav class="navbar bg-dark-subtle py-3">
        <div class="container d-flex justify-content-between align-items-center">
            <!-- Left side: Home button -->
            <a href="index.html" class="btn btn-outline-primary">
                <i class="fas fa-arrow-left"></i>
            </a>

            <!-- Center: Title -->
            <div class="header-title flex-grow-1 text-center">
                <h1 class="gradient-text blog-header-title">
                    <i class="fas fa-blog"></i> DEVLOG
                </h1>
            </div>

            <!-- Right side: Language switcher -->
            <div class="language-switcher">
                <button id="langBtn" class="btn btn-outline-primary">
                    <i class="fas fa-globe"></i> <span id="langText">EN</span>
                </button>
            </div>
        </div>
    </nav>

    <main class="container py-5">
        

        <div class="blog-container">
            <article class="blog-post card bg-dark-subtle border-primary mb-4">
                <div class="card-body">
                    <h2 class="card-title text-primary" data-es="Fundamentos de los LLM: Embeddings y espacios vectorialesüìñ" data-en="Fundamentals of LLM: Embeddings and vector spacesüìñ"></h2>
                    <p class="card-subtitle mb-2 text-muted" data-es="19 de noviembre de 2025" data-en="November 19, 2025"></p>
                    <div class="card-text">
                        <p data-es="Te has preguntado c√≥mo una m√°quina, que solo entiende de n√∫meros y l√≥gica binaria, puede comprender las sutilezas del lenguaje humano? ¬øC√≥mo es que
                        modelos como GPT pueden escribir un poema, resumir un texto o mantener una conversaci√≥n coherente?" data-en="Have you ever wondered how a machine, which only understands numbers and binary logic, can comprehend the subtleties of human language? How is it that models like GPT
                        can write a poem, summarize a text, or hold a coherent conversation?"></p>

                        <p data-es="La respuesta es una combinaci√≥n de matem√°ticas y ling√º√≠stica. En el n√∫cleo de esta capacidad se encuentran dos conceptos clave: los
                        embeddings y los espacios vectoriales. Recientemente, mientras experimentaba en mi propio notebook (tokens.ipynb), pude ver de primera mano c√≥mo estas ideas
                        abstractas funcionan" data-en="The answer is a combination of mathematics and linguistics. At the core of this ability lie two key concepts: embeddings and vector 
                        spaces. Recently, while experimenting in my own notebook (tokens.ipynb), I saw firsthand how these abstract ideas actually work."></p>

                        <p data-es="Una breve mirada a BERT: el modelo detr√°s de los ejemplos" data-en="A brief look to BERT: the model behind the examples"></p>

                        <p data-es="  En mis ejemplos, he utilizado el modelo BERT (Bidirectional Encoder Representations from Transformers), espec√≠ficamente la variante bert-base-uncased.
                        Desarrollado por Google, BERT fue un hito en el procesamiento del lenguaje natural (PLN) por su capacidad de entender el contexto de una palabra de forma
                        bidireccional, es decir, considerando tanto las palabras que la preceden como las que la siguen."
                        data-en="In my examples, I used the BERT model (Bidirectional Encoder Representations from Transformers), specifically the bert-base-uncased variant.
                        Developed by Google, BERT was a milestone in Natural Language Processing (NLP) because of its ability to understand the context of a word bidirectionally‚Äîmeaning it considers both the words that come before it and the ones that come after."></p>

                        <a class="btn btn-outline-info btn-sm mb-3 toggle-btn" data-bs-toggle="collapse" href="#LLM-content" role="button" aria-expanded="false" aria-controls="LLM-content">
                            <span data-es="Mostrar m√°s" data-en="Show more"></span> <i class="fas fa-chevron-down"></i>
                        </a>

                        <div class="collapse" id="LLM-content">
                            <p data-es="BERT se preentren√≥ en un vasto corpus de datos en ingl√©s de manera auto-supervisada. Esto significa que aprendi√≥ del texto sin necesidad de etiquetarlo manualmente
                            utilizando dos tareas principales" data-en="BERT was pre-trained on a vast English corpus in a self-supervised manner. This means it learned directly from text without manually labeled data, using two main tasks:"></p>


                            <p data-es=" 1. Masked Language Modeling (MLM): El modelo toma una oraci√≥n, enmascara aleatoriamente el 15% de las palabras en la entrada, luego ejecuta la oraci√≥n
                            enmascarada completa a trav√©s del modelo y tiene que predecir las palabras enmascaradas originales. Esto le permite aprender relaciones contextuales
                            profundas entre las palabras." data-en="1. Masked Language Modeling (MLM):
                            The model takes a sentence, randomly masks 15% of the words, then processes the entire masked sentence and must predict the original missing words. This allows it to learn deep contextual relationships between words."></p>

                            <p data-es="2. Next Sentence Prediction (NSP): BERT tambi√©n se entrena para predecir si dos oraciones dadas son consecutivas en el texto original o si la oraci√≥n B es una
                            oraci√≥n aleatoria. Esto le ayuda a comprender las relaciones entre oraciones, lo cual es fundamental para tareas que requieren coherencia a nivel de
                            p√°rrafo." data-en="2. Next Sentence Prediction (NSP):
                            BERT is also trained to predict whether two given sentences are consecutive in the original text or if sentence B is a random one. This helps it understand inter-sentence relationships, which is crucial for tasks requiring paragraph-level coherence."></p>

                            <p data-es="La variante bert-base-uncased indica que es la versi√≥n base (m√°s peque√±a y r√°pida) del modelo y que no distingue entre may√∫sculas y min√∫sculas (todas las
                            palabras se convierten a min√∫sculas antes de procesar, es como hacer un .lower() en python). Este modelo es el que nos permite obtener los embeddings que exploraremos a continuaci√≥n."
                            data-en="The bert-base-uncased variant indicates that it is the base (smaller and faster) version of the model, and that it does not distinguish between uppercase and lowercase letters (all words are converted to lowercase before processing ‚Äî like doing .lower() in Python).
                            This is the model that provides the embeddings we will explore below."></p>

                            <img src="images/ML images/BERT.png" class="figure-img img-fluid rounded" alt="BERT">

                            <pre><code class="language-python">
                                from transformers import BertTokenizer

                                #se descarga el tokenizador preentrenado para usarlo
                                tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
                                word = "Hola como estas"
                                #se inicia con el proceso principal de tokenizaci√≥n
                                tokens = tokenizer.tokenize(word)

                                #['ho', '##la', 'como', 'est', '##as']

                                import torch
                                from transformers import BertModel

                                model = BertModel.from_pretrained("bert-base-uncased")

                                #La librer√≠a transformers de huggingface te descarga e instala el modelo que vayas a usar en vez de instalar todo de golpe  
                                #usa tensorflow o pytorch como backend  
                                #mensajes de advertencia, se pueden ignorar

                                #2025-08-11 17:52:58.177918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
                                #WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
                                #E0000 00:00:1754952778.233396    9070 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
                                #E0000 00:00:1754952778.249125    9070 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
                                #W0000 00:00:1754952778.360050    9070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
                                #W0000 00:00:1754952778.360072    9070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
                                #W0000 00:00:1754952778.360074    9070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
                                #W0000 00:00:1754952778.360076    9070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
                                #2025-08-11 17:52:58.374118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
                                #To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

                                print(tokenizer.name_or_path)  # muestra el nombre del modelo de tokenizaci√≥n

                                #busca el ID correspondiente a la palabra "King"
                                king_token_id = tokenizer.convert_tokens_to_ids(["king"])[0] #al ser uncased, no distingue entre may√∫sculas y min√∫sculas
                                print(f"ID de la palabra 'king': {king_token_id}") #da 2332

                                #inicia el proceso de embedding
                                king_embedding = model.embeddings.word_embeddings(torch.tensor([king_token_id]))
                                print(f"Embedding de la palabra 'king':\n{king_embedding}") #da un tensor de 768 dimensiones


                                #los embeddings devuelven un tensor, (una matriz multidimensional)
                                #no los pego todos porque son muy largos, pero el resultado es similar a este:

                                '''
                                bert-base-uncased
                                ID de la palabra 'king': 2332
                                Embedding de la palabra 'king':
                                tensor([[ 1.0459e-02, -4.1597e-02, -2.8762e-02, -2.1271e-03, -3.6137e-02,
                                        -5.9453e-02, -1.8821e-02, -5.3518e-02, -4.5944e-02, -1.0334e-01,
                                        -2.6336e-02, -3.7564e-02,  4.7280e-05, -4.1316e-02,  1.1089e-03,
                                        -3.4041e-02,  3.6455e-03, -4.3182e-03,  4.5244e-02, -3.2792e-03,
                                        -2.9757e-02, -1.2348e-02,  2.7182e-02,  1.8084e-02, -8.3842e-03,
                                        -4.1677e-02,  1.1041e-02,  3.2859e-03,  2.8347e-02, -1.0402e-02,
                                        5.0695e-02, -5.3480e-02, -3.2858e-02, -2.4704e-02, -4.6392e-03,
                                        -9.3113e-03,  3.9658e-02,  1.9593e-02, -3.8411e-03, -2.7013e-02,
                                        -4.1830e-02, -3.2505e-02,  4.3060e-02, -3.7079e-02, -4.0751e-02,
                                        2.2578e-02, -4.2186e-02, -9.9416e-03,  1.2697e-02,  4.2084e-02,
                                        1.2595e-02, -1.4879e-02, -7.6563e-02,  4.5787e-03,  2.0950e-03,
                                        -5.9803e-02, -8.0030e-02, -1.9449e-02]], grad_fn=<EmbeddingBackward0>)
                                ID de la palabra 'man': 2158
                                Embedding de la palabra 'man':
                                tensor([[-7.6646e-03, -3.1175e-02, -6.9835e-03, -6.3297e-03, -1.1371e-02,
                                        -1.7873e-02, -1.1434e-02,  1.0309e-02, -1.0764e-02, -1.9303e-02,
                                        2.6435e-02, -1.0661e-03, -2.0635e-02, -9.0213e-03, -5.0599e-02,
                                        -4.1205e-02, -2.5394e-02, -1.8961e-02,  7.6851e-03,  1.4840e-03,
                                        -5.5302e-02,  3.7641e-03, -7.2016e-02, -7.0809e-03, -6.7614e-02,
                                        4.3692e-02, -2.9522e-02,  1.2630e-02, -1.0300e-02,  2.8095e-02,
                                        1.0858e-02, -2.7949e-02, -3.5180e-02, -1.6189e-02, -1.0497e-02,
                                        -1.5819e-03, -1.0177e-02,  1.2386e-02, -4.2518e-03, -9.6997e-02,
                                        -7.0927e-02,  1.4870e-02,  7.9696e-03,  1.7460e-02, -2.9262e-02,
                                        5.2394e-03,  2.9746e-02, -1.8923e-02,  4.0893e-05, -2.5314e-02,
                                        1.3420e-02,  3.3399e-02,  1.3250e-02, -9.0819e-02,  1.2010e-02,
                                        -7.1084e-02,  5.4406e-03, -2.4264e-02, -2.8006e-02,  3.1375e-02,
                                        4.4374e-03,  3.9825e-02, -6.9961e-02, -3.3235e-03, -1.9383e-02,
                                        7.5572e-03, -4.2687e-02, -4.2618e-02]], grad_fn=<EmbeddingBackward0>)
                                ID de la palabra 'woman': 2450
                                Embedding de la palabra 'woman':
                                tensor([[ 1.2108e-02, -3.0078e-02,  1.8451e-02,  7.0369e-03, -1.1504e-02,
                                        -3.9431e-02, -1.4481e-02,  2.9047e-02,  6.7598e-03, -3.0685e-02,
                                        -1.2698e-02, -5.3419e-02, -1.7568e-02,  4.7697e-02, -6.1417e-02,
                                        -6.1463e-02, -4.8997e-04, -4.8986e-02, -5.5195e-02, -4.3894e-02,
                                        -4.6776e-02, -4.0752e-02, -6.8575e-02, -2.2964e-02, -8.3177e-02,
                                        -1.8618e-02, -1.4952e-02,  1.2415e-03, -1.3154e-03,  2.1765e-03,
                                        6.1241e-02, -4.9063e-02, -2.1670e-02, -5.4052e-03, -3.4771e-02,
                                        -3.4587e-02, -1.0134e-02,  8.1198e-03, -3.4730e-02, -5.6305e-02,
                                        -7.1823e-02,  3.1932e-03, -3.6441e-05, -1.0609e-02, -9.4444e-03,
                                        -1.9346e-02,  2.4101e-02, -9.0241e-03, -2.2390e-02,  1.0220e-02,
                                        -6.3611e-02,  2.6824e-02, -9.4787e-03, -1.7875e-02, -1.5212e-02,
                                        -1.2356e-02,  2.8417e-03, -3.5529e-02, -5.9514e-02,  4.6299e-02,
                                        -4.3715e-02, -6.1539e-02, -1.2442e-02, -2.3420e-03,  2.8436e-02,

                                ID de la palabra 'queen': 3035
                                Embedding de la palabra 'queen':
                                tensor([[ 5.7453e-02, -8.8483e-02, -5.9414e-02,  1.1624e-02, -3.5926e-02,
                                        -8.9322e-02,  5.8101e-02, -3.5651e-03,  3.9393e-02, -8.2666e-02,
                                        -3.2993e-02, -7.5832e-02, -9.6076e-03, -6.7638e-03, -3.8710e-02,
                                        -3.5043e-02,  7.9793e-03, -3.3161e-02, -1.0924e-02, -2.8418e-02,
                                        -1.1208e-02, -2.6782e-02, -1.3545e-02,  5.8899e-02,  1.1604e-02,
                                        -6.2912e-02,  2.5502e-02, -1.7892e-02, -1.5072e-02, -1.8363e-02,
                                        5.2739e-02, -5.0321e-02, -2.7009e-02, -2.8599e-03, -5.5977e-02,
                                        -3.6614e-03,  3.9993e-02,  6.6724e-02, -2.6716e-02, -1.2417e-02,
                                        -9.0510e-02, -1.2854e-02,  1.6648e-02, -3.3466e-02, -2.4335e-02,
                                        5.5003e-02, -4.1292e-02, -1.7306e-02, -4.1601e-02, -1.0229e-02,
                                        9.4465e-03, -6.1036e-02, -3.3751e-02, -3.0292e-02, -1.2840e-02,
                                        -4.8447e-02, -2.1505e-02,  3.2084e-02, -5.3645e-02, -2.4236e-02,
                                '''

                                man_token_id = tokenizer.convert_tokens_to_ids(["man"])[0]
                                print(f"ID de la palabra 'man': {man_token_id}") #da 2158

                                man_embedding = model.embeddings.word_embeddings(torch.tensor([man_token_id]))
                                print(f"Embedding de la palabra 'man':\n{man_embedding}") 

                                woman_token_id = tokenizer.convert_tokens_to_ids(["woman"])[0]
                                print(f"ID de la palabra 'woman': {woman_token_id}") #da 2450

                                woman_embedding = model.embeddings.word_embeddings(torch.tensor([woman_token_id]))
                                print(f"Embedding de la palabra 'woman':\n{woman_embedding}") 

                                queen_token_id = tokenizer.convert_tokens_to_ids(["queen"])[0]
                                print(f"ID de la palabra 'queen': {queen_token_id}") #da 3035

                                queen_embedding = model.embeddings.word_embeddings(torch.tensor([queen_token_id]))
                                print(f"Embedding de la palabra 'queen':\n{queen_embedding}")

                                #orden de los token ids resultantes de las palabras
                                sorted_token_ids = sorted([king_token_id, man_token_id, woman_token_id, queen_token_id])
                                print(f"token IDs ordenados: {sorted_token_ids}\nvalor de cada token ID: {[tokenizer.convert_ids_to_tokens([id])[0] for id in sorted_token_ids]}")

                                #aqui podemos ver que al ser conceptos cercanos, los valores numericos de sus token IDs tambi√©n son cercanos
                                #token IDs ordenados: [2158, 2332, 2450, 3035]
                                #valor de cada token ID: ['man', 'king', 'woman', 'queen']

                                #calcular similitud entre embeddings usando la similitud coseno
                                cos = torch.nn.CosineSimilarity()
                                similarity = cos(king_embedding, queen_embedding)
                                print(f"Similitud entre 'king' y 'queen': {similarity.item()}") #da un valor cercano a 0.8

                                #la similitud de estos 2 conceptos es alta, ya que ambos representan figuras de autoridad en un contexto mon√°rquico
                                #si el valor num√©rico es m√°s alto (cerca a 1.0), significa que los conceptos est√°n m√°s cerca entre si, en el espacio vectorial
                                #Similitud entre 'king' y 'queen': 0.6468513011932373

                                #nuevas palabras a probar
                                dog_token_id = tokenizer.convert_tokens_to_ids(["dog"])[0]
                                print(f"ID de la palabra 'dog': {dog_token_id}")

                                wolf_token_id = tokenizer.convert_tokens_to_ids(["wolf"])[0]
                                print(f"ID de la palabra 'wolf': {wolf_token_id}")

                                cat_token_id = tokenizer.convert_tokens_to_ids(['cat'])[0]
                                print(f"ID de la palabra 'cat': {cat_token_id}")

                                lion_token_id = tokenizer.convert_tokens_to_ids(['lion'])[0]
                                print(f"ID de la palabra 'lion': {lion_token_id}")

                                #orden de los token ids resultantes de las palabras
                                sorted_token_ids = sorted([dog_token_id, wolf_token_id, cat_token_id, lion_token_id])
                                print(f"token IDs ordenados: {sorted_token_ids}\nvalor de cada token ID: {[tokenizer.convert_ids_to_tokens([id])[0] for id in sorted_token_ids]}")

                                #ID de la palabra 'dog': 3899
                                #ID de la palabra 'wolf': 4702
                                #ID de la palabra 'cat': 4937
                                #ID de la palabra 'lion': 7006
                                #token IDs ordenados: [3899, 4702, 4937, 7006]
                                #valor de cada token ID: ['dog', 'wolf', 'cat', 'lion']

                                #palabras personalizadas

                                word1 = input("Enter the first word: ").lower()
                                word2 = input("Enter the second word: ").lower()
                                word3 = input("Enter the third word: ").lower()
                                word4 = input("Enter the fourth word: ").lower()

                                tokenid1 = tokenizer.convert_tokens_to_ids([word1])[0]
                                print(f"ID de la palabra '{word1}': {tokenid1}")

                                tokenid2 = tokenizer.convert_tokens_to_ids([word2])[0]
                                print(f"ID de la palabra '{word2}': {tokenid2}")

                                tokenid3 = tokenizer.convert_tokens_to_ids([word3])[0]
                                print(f"ID de la palabra '{word3}': {tokenid3}")

                                tokenid4 = tokenizer.convert_tokens_to_ids([word4])[0]
                                print(f"ID de la palabra '{word4}': {tokenid4}")

                                sorted_token_ids = sorted([tokenid1, tokenid2, tokenid3, tokenid4])
                                print(f"token IDs ordenados: {sorted_token_ids}\nvalor de cada token ID: {[tokenizer.convert_ids_to_tokens([id])[0] for id in sorted_token_ids]}")
                            </code></pre>

                            <p data-es="<strong>El primer obst√°culo, las palabras no son n√∫meros:</strong>

                            Una computadora no entiende qu√© es un 'gato' o una 'casa'. Para que pueda procesar texto, primero debemos convertir las palabras en n√∫meros. El enfoque m√°s
                            simple ser√≠a asignar un n√∫mero √∫nico a cada palabra del diccionario: 'rey' podr√≠a ser el 50, 'reina' el 51, y 'manzana' el 52." 
                            data-en="<strong>The first hurdle, Words are not numbers:</strong>
                            
                            A computer doesn‚Äôt understand what a ‚Äúcat‚Äù or a ‚Äúhouse‚Äù is. To process text, we must convert words into numbers.
                            The simplest approach would be to assign a unique number to each word in the vocabulary: ‚Äúking‚Äù could be 50, ‚Äúqueen‚Äù 51, and ‚Äúapple‚Äù 52.">
                            </p>

                            <p data-es=" Pero este m√©todo tiene un gran problema: los n√∫meros 50, 51 y 52 no tienen ninguna relaci√≥n entre s√≠. No le dicen a la m√°quina que 'rey' y 'reina' est√°n mucho
                            m√°s relacionados sem√°nticamente que 'rey' y 'manzana'. Aqu√≠ es donde entran en juego los embeddings."

                            data-en="But this method has a major flaw: the numbers 50, 51, and 52 have no relationship to each other. They don‚Äôt tell the machine that ‚Äúking‚Äù and ‚Äúqueen‚Äù are much more semantically related than ‚Äúking‚Äù and ‚Äúapple.‚ÄùThis is where embeddings come into play."></p>

                            <p data-es="<strong>Embeddings, el ADN de las palabras:</strong>
                            
                            Imagina que cada palabra tiene un 'ADN' que define su significado en m√∫ltiples dimensiones. Este ADN es el embedding: una lista de n√∫meros (un vector) que
                            representa a la palabra en un espacio matem√°tico."
                            
                            data-en="Imagine each word has a ‚ÄúDNA‚Äù that defines its meaning across many dimensions.
                            This DNA is the embedding: a list of numbers (a vector) representing the word in a mathematical space."></p>

                            <p data-es="En mi experimentaci√≥n, us√© un modelo pre-entrenado (BERT) para obtener estos vectores. Cuando ped√≠ el embedding para la palabra 'king' (rey), no obtuve un solo
                            n√∫mero, sino un vector con 768 dimensiones."
                            data-en="In my experiments, I used a pre-trained model (BERT) to obtain these vectors. When I asked for the embedding of the word ‚Äúking‚Äù, I didn‚Äôt get a single number ‚Äî I got a vector with 768 dimensions:"></p>

                            <p data-es="Un tensor es basicamente una matr√≠z multidimensional, lo puedes visualizar en c√≥digo en otra entrada de mi blog :)"
                            data-en="A tensor is basically a multidimensional matrix ‚Äî you can visualize it in code in another entry of my blog :)"></p>

                            <pre><code class="language-python">
                                Embedding de la palabra 'king':
                                tensor([[ 1.0459e-02, -4.1597e-02, -2.8762e-02, -2.1271e-03, -3.6137e-02,
                                        -5.9453e-02, -1.8821e-02, -5.3518e-02, -4.5944e-02, -1.0334e-01,
                                        -2.6336e-02, -3.7564e-02,  4.7280e-05, -4.1316e-02,  1.1089e-03,
                                        -3.4041e-02,  3.6455e-03, -4.3182e-03,  4.5244e-02, -3.2792e-03,
                                        ...
                                        -5.9803e-02, -8.0030e-02, -1.9449e-02]], grad_fn=<EmbeddingBackward0>)
                            </code></pre>

                            <p data-es="Cada uno de estos 768 n√∫meros representa una caracter√≠stica abstracta del significado de la palabra, aprendida por el modelo tras analizar miles de millones de
                            textos. Una dimensi√≥n podr√≠a (de forma muy simplificada) representar 'realeza', otra 'g√©nero', otra 'humanidad', etc. Las palabras con significados similares
                            tendr√°n valores parecidos en dimensiones relevantes."
                            
                            data-en="Each of these 768 numbers represents an abstract feature of the word‚Äôs meaning, learned by the model after analyzing billions of texts.
                            One dimension might (very simplistically) represent ‚Äúroyalty,‚Äù another ‚Äúgender,‚Äù another ‚Äúhumanness,‚Äù and so on.
                            Words with similar meanings have similar values in relevant dimensions."></p>

                            <p data-es="Espacios vectoriales, el universo donde viven las palabras"
                            data-en="Vectorial spaces, the universe where words live"></p>

                            <p data-es="Si cada palabra es un punto definido por su vector de embedding, entonces todas las palabras de un idioma viven juntas en un gigantesco 'universo'
                            multidimensional. A esto lo llamamos espacio vectorial."
                            data-en="If every word is a point defined by its embedding vector, then all words in a language live together in a gigantic multidimensional ‚Äúuniverse.‚Äù
                            This is what we call a vector space."></p>

                            <p data-es="Lo realmente asombroso es que en este universo, la distancia y la direcci√≥n importan."
                            data-en="What‚Äôs truly amazing is that in this universe, distance and direction matter:"></p>

                            <p data-es="<strong>1. La Distancia es Significado:</strong> Palabras con significados similares, como 'rey' y 'reina', o 'perro' y 'lobo', estar√°n muy cerca la una de la otra en este
                            espacio. En mi notebook, al calcular la similitud del coseno (una forma de medir la cercan√≠a entre dos vectores) para 'king' y 'queen', obtuve un valor
                            alto (0.64), confirmando su proximidad sem√°ntica."
                            data-en="<strong>1. Distance = Meaning:</strong>
                            Words with similar meanings ‚Äî like ‚Äúking‚Äù and ‚Äúqueen‚Äù or ‚Äúdog‚Äù and ‚Äúwolf‚Äù ‚Äî are close to each other in this space.
                            In my notebook, when I computed the cosine similarity (a measure of vector closeness) between ‚Äúking‚Äù and ‚Äúqueen,‚Äù I got a high value (0.64), confirming their semantic proximity."></p>

                            <pre><code class="language-python">
                                cos = torch.nn.CosineSimilarity()
                                similarity = cos(king_embedding, queen_embedding)
                                print(f"Similitud entre 'king' y 'queen': {similarity.item()}") #da un valor cercano a 0.8

                                #la similitud de estos 2 conceptos es alta, ya que ambos representan figuras de autoridad en un contexto mon√°rquico
                                #si el valor num√©rico es m√°s alto (cerca a 1.0), significa que los conceptos est√°n m√°s cerca entre si, en el espacio vectorial
                                #Similitud entre 'king' y 'queen': 0.6468513011932373
                            </code></pre>

                            <p data-es="<strong>2. La Direcci√≥n es Relaci√≥n:</strong> Las direcciones en este espacio capturan relaciones. El ejemplo m√°s famoso, que pude explorar, es la analog√≠a:"
                            data-en="<strong>2. Direction = Relationship:</strong> Directions in this space capture relationships. The most famous example, which I explored, is the analogy:"></p>

                            <pre><code class="language-python">
                                vector('King') - vector('Man') + vector('Woman') ‚âà vector('Queen')
                            </code></pre>

                            <p data-es="Esto significa que la 'direcci√≥n' que va de 'Hombre' a 'Mujer' es casi la misma que la que va de 'Rey' a 'Reina'. El modelo no sabe qu√© es un rey o una
                            reina, pero ha aprendido que la relaci√≥n de g√©nero que los diferencia es la misma que existe entre un hombre y una mujer. Ha capturado el concepto de 'g√©nero'
                            de forma puramente matem√°tica"
                            data-en="This means the ‚Äúdirection‚Äù that goes from Man to Woman is almost the same as the direction from King to Queen.
                            The model doesn‚Äôt know what a king or queen is ‚Äî but it has learned that the gender relationship between them mirrors the one between man and woman.
                            It has captured the concept of gender in a purely mathematical form"></p>

                            <p data-es="<strong>¬øPor qu√© esto es importante?:</strong> Esta representaci√≥n num√©rica del lenguaje es la base de todo lo que hacen los LLMs. Cuando le pides a un modelo que 'escriba sobre un rey valiente que perdi√≥ su
                            corona', el modelo convierte tus palabras en vectores, opera matem√°ticamente con ellos en su espacio vectorial para 'entender' el contexto y, finalmente,
                            genera una respuesta traduciendo nuevos vectores de vuelta a palabras."
                            data-en="<strong>Why this is so important?:</strong> This numerical representation of language is the foundation of everything LLMs do.
                            When you ask a model to ‚Äúwrite about a brave king who lost his crown‚Äù, the model converts your words into vectors, performs mathematical operations within its vector space to ‚Äúunderstand‚Äù the context, and finally generates an answer by transforming new vectors back into words."></p>
                        </div>
                    </div>
                </div>
            </article>
            <article class="blog-post card bg-dark-subtle border-primary mb-4">
                <div class="card-body">
                    <h2 class="card-title text-primary" data-es="√Ålgebra lineal para Machine Learningü§ñ" data-en="Linear Algebra for Machine Learningü§ñ"></h2>
                    <p class="card-subtitle mb-2 text-muted" data-es="18 de noviembre de 2025" data-en="November 18, 2025"></p>
                    <div class="card-text">
                        <p data-es="Esta entrada corresponde a una libreta de jupyter explicando a detalle los distintos elementos que conforman las estructuras de datos usadas en algebra lineal para machine learning." data-en="This entry corresponds to a Jupyter notebook explaining in detail the different elements that make up the data structures used in linear algebra for machine learning."></p>
                        <a class="btn btn-outline-info btn-sm mb-3 toggle-btn" data-bs-toggle="collapse" href="#ML-content" role="button" aria-expanded="false" aria-controls="ML-content">
                            <span data-es="Mostrar m√°s" data-en="Show more"></span> <i class="fas fa-chevron-down"></i>
                        </a>
                        <div class="collapse" id="ML-content">
                            <pre><code class="language-python">
                                #un escalar es un tipo de variable que solo tiene un valor, puede ser int, float, str, bool
                                #es simplemente un n√∫mero real que se utiliza para: multplicar vectores o matrices o cambiar su magnitud
                                escalar = 2.65
                                print(f"Escalar float: {escalar}")
                                escalar_bool = True
                                print(f"Escalar bool: {escalar_bool}")

                                #Verificar tipos de variables
                                print(f"Tipo de escalar: {type(escalar)}")
                                print(f"Tipo de escalar: {type(escalar_bool)}")

                                #un vector es un conjunto de numeros reales
                                #Una matriz es una estructura bidimensional de n√∫meros reales, que puede representarse como un conjunto ordenado de vectores fila o columna.
                                #Un tensor es una estructura multidimensional que generaliza a vectores y matrices a m√°s dimensiones.

                                #importaciones
                                import numpy as np

                                vector = np.array([1, 2, 3, 4])
                                print(f"Vector: {vector}")
                                #.shape() nos devuelve las dimensiones del objeto en cuesti√≥n
                                print(f"\nDimensiones de Vector: {np.shape(vector)}") #(4,) -> 4 elementos
                                print(f"\nCantidad de elementos en Vector: {np.size(vector)}")

                                matriz = np.array([[1, 2, 3],
                                                    [4, 5, 6],
                                                    [7, 8, 9]])

                                print(f"\nMatriz: {matriz}")
                                print(f"\nDimensiones de Matr√≠z: {np.shape(matriz)}") #(3, 3) -> 3 filas, 3 columnas
                                print(f"\nCantidad de elementos en Matr√≠z: {np.size(matriz)}")

                                tensor = np.array([
                                    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                                    [[10, 11, 12], [13, 14, 15], [16, 17, 18]],
                                    [[19, 20, 21], [22, 23, 24], [25, 26, 27]]
                                ])
                                print(f"\nTensor:\n{tensor}")
                                print(f"\nDimensiones de Tensor: {np.shape(tensor)}") #(3, 3, 3) ->3 matrizes, 3 filas, 3 columnas
                                print(f"\nCantidad de elementos en Tensor: {np.size(tensor)}")

                                import matplotlib.pyplot as plt

                                #graficar el tensor estructurado mediante escala de grises
                                plt.imshow(tensor, interpolation='nearest')
                                plt.show()
                            </code></pre>

                            <figure class="figure-text-center">
                                <img src="images/ML images/grey_scale.webp" class="figure-img img-fluid rounded">
                                <figcaption class="figure-caption text-light-emphasis"></figcaption>
                            </figure>

                            <pre><code class="language-python">
                                tensor_rgb = np.array([
                                    [[0, 255, 0], [0, 255, 0], [0, 255, 0]],
                                    [[0, 159, 193], [0, 159, 193], [0, 159, 193]],
                                    [[0, 0, 255], [0, 0, 255], [0, 0, 255]]
                                ])

                                #matplotlib interpreta cada vector como colores rgb
                                plt.imshow(tensor_rgb, interpolation='nearest')
                                plt.show()
                            </code></pre>

                            <figure class="figure text-center">
                                <img src="images/ML images/rgb_example.webp" class="figure-img img-fluid rounded">
                                <figcaption class="figure-caption text-light-emphasis"></figcaption>
                            </figure>

                            <pre><code class="language-python">
                                #transposici√≥n de vectores y matrices
                                escalar = 2.65

                                vector = np.array([1, 2, 3, 4])
                                vector1  = np.array([5, 6, 7, 8])

                                matriz = np.array([[1, 2],
                                                [3, 4],
                                                [5, 6]])
                                print(f"Matr√≠z original:\n{matriz}")
                                print(f"\nDimensiones de la Matr√≠z: {np.shape(matriz)}")
                                matriz_t = np.transpose(matriz)
                                print(f"\nMatriz transpocisionada:\n{matriz_t}")
                                print(f"\nDimensiones de la Matr√≠z transposicionada: {np.shape(matriz_t)}")
                                tensor = np.array([
                                    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                                    [[10, 11, 12], [13, 14, 15], [16, 17, 18]],
                                    [[19, 20, 21], [22, 23, 24], [25, 26, 27]]
                                ])
                                print(f"\nTensor:\n{tensor}")
                                print(f"\nDimensiones del tensor: {np.shape(tensor)}")
                                tensor_t = np.transpose(tensor)
                                print(f"\nTensor trasposicionado:\n{tensor_t}")
                                print(f"\nDimensiones del tensor transposicionado:\n{np.shape(tensor_t)}")

                                #suma de matr√≠ces (IMPORTANTE: para hacer una suma entre 2 o m√°s matrices, vectores o tensores, tienen que tener las mismas dimensiones, en este caso (2x2))
                                a = np.array([[1, 2, 3], [4, 5, 6],
                                            [7, 8, 9], [10, 11, 12]])
                                print(f"\nDimensiones de la Matr√≠z a: {np.shape(a)}")

                                b = np.array([[13, 14, 15], [16, 17, 18],
                                            [19, 20, 21], [22, 23, 24]])
                                print(f"\nDimensiones de la Matr√≠z b: {np.shape(b)}")

                                c = a + b

                                print(f"\nSuma de las 2 matrices:\n{c}")

                                d = matriz + escalar

                                print(f"\nSuma de la matr√≠z m√°s el escalar:\n{d}")

                                #suma de vectores
                                e = vector + vector1
                                print(f"\nSuma de 2 vectores:\n{e}")

                                #suma de vectores o matrices con dimensiones distintas
                                #reglas del broadcasting de Python

                                vector2 = np.array([3, 4, 5]) # vector con 3 valores

                                print(f"\nVector 2 inicial:\n{vector2}")

                                matriz2 = np.array([[1, 2], # matr√≠z de dimensi√≥n 3x2
                                                    [3, 4],
                                                    [5, 6]])
                                print(f"\nMatr√≠z 2 inicial:\n{matriz2}")

                                matriz2_t = np.transpose(matriz2) # matr√≠z de dimensi√≥n 2x3
                                print(f"\nMatr√≠z 2 transposicionada:\n{matriz2_t}")

                                #lo que queremos hacer:
                                #sumar      ([3, 4, 5]) + ([[1, 2],   ##ESTO NO SE PUEDE DEBIDO A QUE NO PODEMOS ASIGNAR CORRECTAMENTE LOS 3 VALORES NECESARIOS PARA CADA OPERACI√ìN
                                #                           [3, 4],
                                #                           [5, 6]])

                                #sumar      ([3, 4, 5]) + [[1 3 5]  ##ESTO SI SE PUEDE DEBIDO A QUE PODEMOS ASIGNAR CORRECTAMENTE LOS 3 VALORES NECESARIOS PARA CADA OPERACI√ìN
                                #                          [2 4 6]] ##EL BROADCASTING SE ENCARGA DE EXTENDER UN VECTOR O MATR√çZ QUE LO NECESITE PARA PODER HACER LA OPERACI√ìN

                                #efectuamos la suma correspondiente

                                suma_final = vector2 + matriz2_t
                                print(f"\nSuma final resultante:\n{suma_final}")

                                import matplotlib.pyplot as plt
                                import matplotlib.image as mpimg
                                #multiplicaci√≥n de matrices y vectores
                                escalar = 2.65 #escalar = Œª

                                vector = np.array([1, 2])
                                vector1  = np.array([5, 6, 7, 8])

                                matriz = np.array([[1, 2],
                                                [3, 4],
                                                [5, 6]])

                                multiplicacion = vector * matriz # EN ESTE CASO PYTHON HACE BROADCASTING INTERNAMENTE
                                print(f"\n Resultado de la multiplicaci√≥n:\n{multiplicacion}")

                                #producto interno nos devuelve un vector con los valores resultantes de la suma de los productos de cada fila

                                #           ([[1, 2],               1*1 + 2*2 = 5
                                #             [3, 4], * ([1, 2]) =  3*1 + 4*2 = 11 = [5, 11, 17]
                                #             [5, 6]])              5*1 + 6*2 = 17

                                producto_interno = np.dot(matriz, vector)
                                print(f"\nProducto interno resultante:\n{producto_interno}")

                                #multiplicaci√≥n entre matr√≠ces
                                matriz_a = np.array([[1, 2, 3],
                                                    [4, 5, 6],
                                                    [7, 8, 9],
                                                    [10, 11, 12]])
                                print(f"\nDimensiones de matr√≠z a: {np.shape(matriz_a)}")

                                matriz_b = np.array([[13, 14, 15],
                                                    [16, 17, 18],
                                                    [19, 20, 21],
                                                    [22, 23, 24]])
                                print(f"\nDimensiones de matr√≠z b: {np.shape(matriz_b)}")

                                matriz_c = np.array([[2, 3],
                                                    [5, 7],
                                                    [11, 13]])
                                print(f"\nDimensiones de matr√≠z c: {np.shape(matriz_c)}")

                                multip = matriz_a * matriz_b
                                print(f"\nResultado de la multiplicaci√≥n elemento por elemento entre 2 matr√≠ces:\n{multip}")

                                matriz_b_t = np.transpose(matriz_b)
                                print(f"\nMatr√≠z b transpuesta:\n{matriz_b_t}")
                                print(f"\nDimensiones de la matr√≠z b transpuesta:\n{np.shape(matriz_b_t)}")

                                multip = np.dot(matriz_a, matriz_b_t)#multiplicaci√≥n de matrices compatible (4*3)(3*4)
                                print(f"\nResultado de la multiplicaci√≥n tradicional entre matriz a y matriz b:\n{multip}")

                                #producto interno matriz_a * matriz_c ##CUANDO TENGO, COMO EN ESTE CASO, UNA ALINEACI√ìN EN 2 VALORES, SE PUEDE EFECTUAR EL PI (4, 3)(3, 2)
                                #                   ([[1, 2, 3],          ([[2, 3],       1*2 + 2*5 + 3*11 = 45  -  1*3 + 2*7 + 3*13 = 56                 [[45 56]
                                #                     [4, 5, 6],      *     [5, 7],    =  4*2 + 5*5 + 6*11 = 99  -  4*3 + 5*7 + 6*13 = 125          =      [99 125]
                                #                     [7, 8, 9],            [11, 13]])    7*2 + 8*5 + 9* 11 = 153  -  7*3 + 8*7 + 9*13 = 194               [153 194]
                                #                     [10, 11, 12]])                      10*2 + 11*5 + 12*11 = 207  -  10*3 + 11*7 + 12*13 = 263          [207 263]]

                                producto_interno = np.dot(matriz_a, matriz_c)
                                print(f"\nProducto interno resultante:\n{producto_interno}")


                                img = mpimg.imread('producto interno.png')
                                plt.figure(figsize=(10, 10))
                                plt.imshow(img)
                                plt.show()

                                #propiedades del producto interno

                                A = np.array([[2, 3],
                                            [5, 7],
                                            [11, 13]])
                                print(f"\nDimensiones de la matr√≠z A:\n{np.shape(A)}")

                                B = np.array([[1, 3],
                                            [2, 1]])
                                print(f"\nDimensiones de la matr√≠z B\n{np.shape(B)}")

                                C = np.array([[3, 1],
                                            [4, 2]])
                                print(f"Dimensiones de la matr√≠z C:\n{np.shape(C)}")
                                #propiedad asociativa
                                #RECORDATORIO: Para que puedas multiplicar dos matrices A*B, se debe cumplir:
                                #El n√∫mero de columnas de A = n√∫mero de filas de B    Si A es de forma (m * n) y B es de forma (n * p), entonces AB es de forma (m √ó p)
                                #El orden de agrupaci√≥n no afecta el resultado. (A * B) * C = A * (B * C)

                                #A*(B*C) = (A*B)*C

                                #A * (B * C)
                                ABC = A.dot(B.dot(C))
                                print(f"\nMultiplicaci√≥n: A*(B*C):\n{ABC}")

                                #(A * B) * C
                                AB_C = A.dot(B).dot(C)
                                print(f"\nMultiplicaci√≥n: (A*B)*C:\n{AB_C}")

                                #comprobamos la igualdad entre las 2 matr√≠ces resultantes
                                print(f"\nIgualdad entre ABC y AB_C: {np.array_equal(ABC, AB_C)}")

                                # La propiedad distributiva establece que:
                                # A * (B + C) = (A * B) + (A * C)
                                # Esto significa que la multiplicaci√≥n de una matriz A por la suma de dos matrices B y C
                                # es igual a la suma de la multiplicaci√≥n de A por B y la multiplicaci√≥n de A por C.

                                D = A.dot(B+C)
                                E = (A.dot(B)) + (A.dot(C))

                                print(f"\nA*(B+C):\n{D}")
                                print(f"\n(A*B)+(A*C):\n{E}")

                                #comprobamos la igualdad entre las 2 matrices resultantes
                                print(f"\nIgualdad entre D y E: {np.array_equal(D, E)}")

                                # La propiedad conmutativa establece que:
                                # A * B = B * A
                                # Esto significa que el orden de la multiplicaci√≥n no afecta al resultado.
                                # Sin embargo, esta propiedad no se cumple en la multiplicaci√≥n de matrices,
                                # pero s√≠ en la multiplicaci√≥n de vectores (producto escalar).

                                F = np.dot(B, C)
                                print(f"\nProducto interno B*C:\n{F}\ny sus dimensiones:\n{np.shape(F)}")
                                G = np.dot(C, B)
                                print(f"\nProducto interno C*B:\n{G}\ny sus dimensiones:\n{np.shape(G)}")

                                #comprobamos la igualdad entre las 2 matrices resultantes
                                print(f"\nIgualdad entre F y G: {np.array_equal(F, G)}") ##FALSE, NO APLICA CON MULTIPLICACI√ìN DE MATRICES

                                #LA MULTIPLICACI√ìN DE VECTORES SI ES CONMUTATIVA

                                vector1 = np.array([3, 7]) #multiplicaci√≥n ([3, 7]) * ([3, 5]) = 3*3 + 7*5 = 44
                                vector2 = np.array([3, 5]) #multiplicaci√≥n ([3, 5]) * ([3, 7]) = 3*3 + 5*7 = 44

                                H = np.dot(vector1, vector2)
                                print(f"\nProducto interno vector1 * vector2:\n{H}\ny sus dimensiones:\n{np.shape(H)}")
                                I = np.dot(vector2, vector1)
                                print(f"\nProducto interno vector2 * vector1:\n{I}\ny sus dimensiones:\n{np.shape(I)}")
                            </code></pre>
                        </div>
                    </div>
                </div>
            </article>
            <article class="blog-post card bg-dark-subtle border-primary mb-4">
                <div class="card-body">
                    <h2 class="card-title text-primary" data-es="Creaci√≥n del Blog" data-en="Blog Creation"></h2>
                    <p class="card-subtitle mb-2 text-muted" data-es="15 de noviembre de 2025" data-en="November 15, 2025"></p>
                    <div class="card-text">
                        <p data-es="¬°Bienvenido a mi nuevo blog! He decidido crear este espacio para documentar el proceso de desarrollo de mis proyectos, compartir ideas y publicar los avances." data-en="Welcome to my new blog! I've decided to create this space to document the development process of my projects, share ideas, and post updates."></p>
                        <p data-es="Para empezar, he creado esta misma p√°gina usando HTML y Bootstrap, manteniendo el estilo de mi portafolio principal. Aqu√≠ podr√°s ver c√≥mo evolucionan mis proyectos como <strong>TDMBOTüí†</strong>, <strong>Berto AIüå±</strong> y otros experimentos en los que trabaje." data-en="To start, I've created this very page using HTML and Bootstrap, maintaining the style of my main portfolio. Here you'll be able to see how my projects like <strong>TDMBOTüí†</strong>, <strong>Berto AIüå±</strong>, and other experiments I work on evolve."></p>
                    </div>
                </div>
            </article>

            <article class="blog-post card bg-dark-subtle border-info mb-4">
                <div class="card-body">
                    <h2 class="card-title text-info" data-es="Proceso de desarrollo de RobTopLvlIDüîé" data-en="Development Process for RobTopLvlIDüîé"></h2>
                    <p class="card-subtitle mb-2 text-muted" data-es="22 de mayo de 2025" data-en="May 22, 2025"></p>
                    
                    <div class="card-text">
                        <p data-es="Hace unos meses, cuando comenc√© a explorar el campo de la inteligencia artificial, me pregunt√© si ser√≠a posible desarrollar un modelo capaz de reconocer niveles de Geometry Dash. Mi objetivo no era aprovechar esto para obtener una ventaja injusta en Sparky, especialmente considerando las evidentes limitaciones de hardware, incluso utilizando recursos en la nube.
                        Finalmente, decid√≠ basar el proyecto en el modelo pre-entrenado MobileNetV2 de Keras, aprovechando redes neuronales convolucionales para el reconocimiento de im√°genes. El c√≥digo completo puede encontrarse en el repositorio GDLvlDetector.

                        Inicialmente intent√© construir la red desde cero usando TensorFlow, y sorprendentemente funcion√≥ bastante bien reconociendo alrededor de dos a cinco niveles como m√°ximo. Sin embargo, el principal reto con este enfoque fue la gran cantidad de datos requerida y las limitaciones de hardware.
                        En las siguientes secciones explicar√© cada fase del proceso de entrenamiento que llev√© a cabo." 
                        
                        data-en="
                        A few months ago, as I began exploring the field of artificial intelligence, I wondered whether it would be possible to develop a model capable of recognizing Geometry Dash levels. My goal was not to exploit this for unfair advantage in Sparky, especially considering the evident hardware limitations even when utilizing cloud resources. Ultimately, I decided to base the project on the pre-trained MobileNetV2 model from Keras, leveraging convolutional neural networks for image recognition. The complete code can be found in the repository GDLvlDetector. 
                        
                        Initially, I attempted to build the network from scratch using TensorFlow, which surprisingly performed quite well in recognizing around two to five levels at most. However, the primary challenge with this approach was the sheer volume of data required and the hardware constraints. In the following sections, I will explain each phase of the training process I undertook."></p>

                        <a class="btn btn-outline-info btn-sm mb-3 toggle-btn" data-bs-toggle="collapse" href="#robtop-content" role="button" aria-expanded="false" aria-controls="robtop-content">
                            <span data-es="Mostrar m√°s" data-en="Show more"></span> <i class="fas fa-chevron-down"></i>
                        </a>

                        <div class="collapse" id="robtop-content">
                            <div class="ratio ratio-16x9 my-4 video-frame">
                                <iframe src="https://www.youtube.com/embed/n_L2AG_-dxs?si=HRqAvSSNpA7IZpsU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                            </div>

                            <p data-es="Como en cualquier proyecto de machine learning, el primer paso que debe realizarse‚Äîy el que en √∫ltima instancia determinar√° la calidad del modelo‚Äîes reunir los datos de entrenamiento.

                            Para este proyecto, pas√© varios d√≠as grabando todos los niveles que el modelo deber√≠a reconocer posteriormente usando im√°genes. Sin embargo, no pod√≠a entrenar el modelo usando directamente el metraje de los videos, lo que nos lleva al segundo paso." 
                            
                            data-en="As with any machine learning project, the initial step that must be taken‚Äîand the one that will ultimately determine the quality of the model‚Äîis gathering the training data. 
                            
                            For this project, I spent several days recording all the levels that the model would later recognize using images. However, I could not train the model using video footage directly, which leads us to the second step.
                            The proper way to train a convolutional neural network is by using images. Therefore, I extracted frames from the videos I had recorded earlier. Naturally, I didn‚Äôt do this manually but instead used OpenCV with the following script:"></p>

                            <pre><code class="language-python">
                                import os
                                import cv2

                                def extract_frames(video_path, output_folder, interval=30):
                                    os.makedirs(output_folder, exist_ok=True)

                                    cap = cv2.VideoCapture(video_path)

                                    frame_count = 0
                                    saved_frames = 0

                                    while cap.isOpened(): 
                                        ret, frame = cap.read()
                                        if not ret:
                                            break

                                        if frame_count % interval == 0:
                                            filename = os.path.join(output_folder, f"{os.path.basename(video_path).split('.')[0]}_frame_{saved_frames}.jpg")
                                            cv2.imwrite(filename, frame)
                                            saved_frames += 1

                                        frame_count += 1

                                    cap.release()
                            </code></pre>
                            <p data-es="En el paso anterior, las im√°genes extra√≠das de los fotogramas fueron guardadas ordenadamente en carpetas nombradas seg√∫n cada nivel.
                            Ahora es necesario preparar los datos de la manera m√°s √≥ptima para usarlos con el modelo MobileNetV2, de forma que durante el proceso de convoluci√≥n pueda clasificar y reconocer patrones correctamente.
                            Esto implica tomar en cuenta varios aspectos, como:
                            tama√±o de las im√°genes, tama√±o de los lotes, tama√±os de los vectores, canales de color y muchos otros detalles tediosos pero esenciales."
                            
                            data-en="In the previous step, the images from the frames were saved in an orderly manner into folders named after each level. Now, it is necessary to prepare the data in the most optimal way for use with the MobileNetV2 model, so that during the convolution process it can classify and recognize patterns correctly. This involves taking several aspects into account, such as image size, batch size, vector sizes, color channels, and many other tedious but essential details. The following script details this process:"></p>
                            <pre><code class="language-python">
                                import tensorflow as tf
                                import numpy as np
                                import json
                                import matplotlib.pyplot as plt
                                from keras.src.legacy.preprocessing.image import ImageDataGenerator
                                from keras.src.callbacks import EarlyStopping, ModelCheckpoint
                                from keras.src.applications.mobilenet_v2 import preprocess_input, MobileNetV2
                                from keras.src import layers, models

                                # Path to the train data
                                data_path = "vidframes"

                                # Callbacks
                                callbacks = [
                                    EarlyStopping(patience=10, restore_best_weights=True),
                                    ModelCheckpoint("best_model.keras", save_best_only=True)
                                ]

                                # Data Augmentation + Preprocess MobileNetV2
                                datagen = ImageDataGenerator(
                                    preprocessing_function=preprocess_input,
                                    validation_split=0.2,
                                    rotation_range=15,
                                    width_shift_range=0.1,
                                    height_shift_range=0.1,
                                    shear_range=0.1,
                                    zoom_range=0.2,
                                    horizontal_flip=True,
                                    brightness_range=[0.8, 1.2],
                                    fill_mode='nearest'
                                )

                                train_data = datagen.flow_from_directory(
                                    data_path,
                                    target_size=(160, 160),  # Size for MobileNetV2
                                    batch_size=32,
                                    class_mode='categorical',
                                    subset='training'
                                )

                                val_data = datagen.flow_from_directory(
                                    data_path,
                                    target_size=(160, 160),
                                    batch_size=32,
                                    class_mode='categorical',
                                    subset='validation'
                                )
                            </code></pre>

                            <p data-es="En este paso, el modelo ya est√° listo para comenzar su proceso de entrenamiento.
                            Despu√©s de preparar los datos, la red neuronal puede generalizar m√°s informaci√≥n para reconocer casos especiales, como si la imagen est√° rotada o deformada, entre otros.

                            En este punto uso un modelo pre-entrenado de Keras llamado MobileNetV2. Al cargarlo, esto me permite entrenar mi modelo utilizando la t√©cnica de transfer learning, evitando crear mi propia red neuronal convolucional desde cero y lidiar con todos los problemas que eso implica.
                            
                            Importar modelos pre-entrenados MobileNetV2 desde keras y cargar el modelo en una variable:"

                            data-en="Model Training In this step, the model is ready to begin its training process. After data preparation, the neural network can generalize to more information to order to recognize more special cases, such as if an image if rotated or deformed, among others. At this point i use an pre-trained Keras model called MobileNetV2. By loading it, this will me train my model using the transfer learning technique so i don't create my own Convolutional Neuronal Network from scratch and deal with all the problems that entails.

                            Import MobileNetV2 Pre-trained models from keras and load the model in a variable:"></p>

                            <pre><code class="language-python">
                                from keras.src.legacy.preprocessing.image import ImageDataGenerator
                                from keras.src.callbacks import EarlyStopping, ModelCheckpoint
                                from keras.src.applications.mobilenet_v2 import preprocess_input, MobileNetV2
                                from keras.src import layers, models

                                base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))
                            </code></pre>

                            <p data-es="Proceso de Transfer Learning y configuraci√≥n"
                            data-en="Transfer Learning Process and configutation"></p>

                            <pre><code class="language-python">
                                for layer in base_model.layers:
                                    layer.trainable = False

                                for layer in base_model.layers[-30:]:  # Latest 30 layers
                                    layer.trainable = True

                                # Complete Model
                                model = models.Sequential([
                                    base_model,
                                    layers.GlobalAveragePooling2D(),
                                    layers.Dense(256, activation='relu'),
                                    layers.Dropout(0.5),
                                    layers.Dense(train_data.num_classes, activation='softmax')  
                                ])
                            </code></pre>

                            <p data-es="Proceso de compilaci√≥n y entrenamiento"
                            data-en="Compile and training process"></p>

                            <pre><code class="language-python">
                                # Compile
                                model.compile(
                                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
                                    loss='categorical_crossentropy',
                                    metrics=['accuracy']
                                )

                                # Training
                                history = model.fit(train_data, validation_data=val_data, epochs=50, callbacks=callbacks)
                                with open("train_history.json", "w").
                                    json.dump(history.history, f)

                                # Save Model .keras
                                model.save("gd_level_classifier.keras")
                            </code></pre>
                            
                        </div>
                    </div>
                </div>
            </article>

        </div>
    </main>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Prism.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/normalize-whitespace/prism-normalize-whitespace.min.js"></script>
    <!-- Custom JS -->
    <script src="portfolio-script.js"></script>
    <script>
        // Configuraci√≥n de Prism Normalize Whitespace
        Prism.plugins.NormalizeWhitespace.setDefaults({
            'remove-trailing': true,
            'remove-indent': true,
            'left-trim': true,
            'right-trim': true,
        });
    </script>
</body>
</html>